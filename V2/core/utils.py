"""
Utilitaires pour UMAP vs t-SNE Explorer - Version Compl√®te
=========================================================

Fonctions utilitaires communes :
- Gestion des seeds pour reproductibilit√©
- Validation des param√®tres
- Gestion de l'interface utilisateur Streamlit
- Export/Import de sessions
- Palettes de couleurs et formatage
"""

import numpy as np
import pandas as pd
import streamlit as st
import random
import os
import json
import io
from typing import Dict, List, Any, Optional, Tuple, Union
import warnings
from pathlib import Path

def seed_everything(seed: int = 42):
    """
    Configure tous les g√©n√©rateurs de nombres al√©atoires pour la reproductibilit√©.
    
    Parameters
    ----------
    seed : int, default=42
        Graine al√©atoire √† utiliser
    """
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    
    try:
        import tensorflow as tf
        tf.random.set_seed(seed)
    except ImportError:
        pass
    
    try:
        import torch
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
    except ImportError:
        pass

def validate_tsne_parameters(params: Dict[str, Any], n_samples: int) -> List[str]:
    """
    Valide les param√®tres t-SNE et retourne les erreurs.
    
    Parameters
    ----------
    params : Dict[str, Any]
        Param√®tres t-SNE √† valider
    n_samples : int
        Nombre d'√©chantillons
        
    Returns
    -------
    errors : List[str]
        Liste des erreurs de validation
    """
    errors = []
    
    # Validation de perplexity
    perplexity = params.get('perplexity', 30)
    max_perplexity = (n_samples - 1) // 3
    
    if perplexity >= max_perplexity:
        errors.append(
            f"‚ö†Ô∏è perplexity ({perplexity}) trop √©lev√©e pour n_samples={n_samples}. "
            f"Maximum recommand√©: {max_perplexity-1}"
        )
    
    if perplexity < 5:
        errors.append("‚ö†Ô∏è perplexity < 5 peut donner des r√©sultats instables")
    
    # Validation de learning_rate
    learning_rate = params.get('learning_rate', 'auto')
    if learning_rate != 'auto' and isinstance(learning_rate, (int, float)):
        if learning_rate < 1:
            errors.append("‚ö†Ô∏è learning_rate tr√®s faible peut ralentir la convergence")
        elif learning_rate > 1000:
            errors.append("‚ö†Ô∏è learning_rate tr√®s √©lev√© peut causer de l'instabilit√©")
    
    # Validation de max_iter
    max_iter = params.get('max_iter', 1000)
    if max_iter < 250:
        errors.append("‚ö†Ô∏è max_iter < 250 peut √™tre insuffisant pour la convergence")
    
    return errors

def validate_umap_parameters(params: Dict[str, Any], n_samples: int) -> List[str]:
    """
    Valide les param√®tres UMAP et retourne les avertissements.
    
    Parameters
    ----------
    params : Dict[str, Any]
        Param√®tres UMAP √† valider
    n_samples : int
        Nombre d'√©chantillons
        
    Returns
    -------
    warnings : List[str]
        Liste des avertissements
    """
    warnings_list = []
    
    # Validation de n_neighbors
    n_neighbors = params.get('n_neighbors', 15)
    if n_neighbors >= n_samples:
        warnings_list.append(
            f"‚ö†Ô∏è n_neighbors ({n_neighbors}) >= n_samples ({n_samples}). "
            f"Maximum: {n_samples - 1}"
        )
    elif n_neighbors > n_samples // 2:
        warnings_list.append(
            f"‚ö†Ô∏è n_neighbors tr√®s √©lev√© ({n_neighbors}) peut sur-lisser la structure locale"
        )
    elif n_neighbors < 2:
        warnings_list.append("‚ö†Ô∏è n_neighbors < 2 peut causer des erreurs")
    
    # Validation de min_dist vs spread
    min_dist = params.get('min_dist', 0.1)
    spread = params.get('spread', 1.0)
    
    if min_dist > spread:
        warnings_list.append(
            f"‚ö†Ô∏è min_dist ({min_dist}) > spread ({spread}) peut causer des probl√®mes"
        )
    
    if min_dist < 0:
        warnings_list.append("‚ö†Ô∏è min_dist < 0 n'est pas recommand√©")
    
    # Validation de n_epochs
    n_epochs = params.get('n_epochs', 200)
    if n_epochs < 50:
        warnings_list.append("‚ö†Ô∏è n_epochs < 50 peut √™tre insuffisant")
    elif n_epochs > 1000 and n_samples < 5000:
        warnings_list.append("‚ö†Ô∏è n_epochs √©lev√© peut √™tre inutile pour des petits datasets")
    
    return warnings_list

class UIUtils:
    """Utilitaires pour l'interface utilisateur Streamlit."""
    
    @staticmethod
    def display_metrics_card(algorithm_name: str, 
                           metrics: Dict[str, float],
                           clustering_results: Dict[str, Any]):
        """
        Affiche une carte de m√©triques dans Streamlit.
        
        Parameters
        ----------
        algorithm_name : str
            Nom de l'algorithme
        metrics : Dict[str, float]
            M√©triques √† afficher
        clustering_results : Dict[str, Any]
            R√©sultats de clustering
        """
        with st.container():
            st.markdown(f"**üìä M√©triques {algorithm_name}**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Trustworthiness", f"{metrics.get('trustworthiness', 0):.4f}")
                st.metric("KNN Accuracy", f"{metrics.get('knn_accuracy', 0):.4f}")
                st.metric("Silhouette Score", f"{metrics.get('silhouette_score', 0):.4f}")
            
            with col2:
                st.metric("Continuity", f"{metrics.get('continuity', 0):.4f}")
                st.metric("Shepard Correlation", f"{metrics.get('shepard_correlation', 0):.4f}")
                
                # Info clustering
                if clustering_results:
                    best_algo = clustering_results.get('best_algorithm', 'unknown')
                    n_clusters = clustering_results.get('n_clusters', 0)
                    st.metric("Clustering", f"{best_algo.upper()} ({n_clusters} clusters)")

        return None  # √âviter tout retour de DeltaGenerator
    
    @staticmethod
    def validate_parameters(params: Dict[str, Dict[str, Any]], n_samples: int) -> List[str]:
        """
        Valide tous les param√®tres et retourne les avertissements.
        
        Parameters
        ----------
        params : Dict[str, Dict[str, Any]]
            Param√®tres UMAP et t-SNE
        n_samples : int
            Nombre d'√©chantillons
            
        Returns
        -------
        warnings : List[str]
            Liste de tous les avertissements
        """
        all_warnings = []
        
        if 'umap' in params:
            umap_warnings = validate_umap_parameters(params['umap'], n_samples)
            all_warnings.extend([f"UMAP: {w}" for w in umap_warnings])
        
        if 'tsne' in params:
            tsne_warnings = validate_tsne_parameters(params['tsne'], n_samples)
            all_warnings.extend([f"t-SNE: {w}" for w in tsne_warnings])
        
        return all_warnings
    
    @staticmethod
    def create_comparison_table(umap_metrics: Dict[str, float],
                              tsne_metrics: Dict[str, float], 
                              umap_clustering: Dict[str, Any],
                              tsne_clustering: Dict[str, Any],
                              umap_time: float,
                              tsne_time: float) -> pd.DataFrame:
        """
        Cr√©e un tableau comparatif des r√©sultats.
        
        Parameters
        ----------
        umap_metrics : Dict[str, float]
            M√©triques UMAP
        tsne_metrics : Dict[str, float]
            M√©triques t-SNE
        umap_clustering : Dict[str, Any]
            R√©sultats clustering UMAP
        tsne_clustering : Dict[str, Any]
            R√©sultats clustering t-SNE
        umap_time : float
            Temps UMAP
        tsne_time : float
            Temps t-SNE
            
        Returns
        -------
        df : pd.DataFrame
            Tableau de comparaison
        """
        def get_winner(umap_val, tsne_val, lower_is_better=False):
            if lower_is_better:
                return "UMAP" if umap_val < tsne_val else "t-SNE"
            else:
                return "UMAP" if umap_val > tsne_val else "t-SNE"
        
        data = []
        
        # M√©triques principales
        metrics_config = [
            ("Trustworthiness", "trustworthiness", False),
            ("Continuity", "continuity", False),
            ("KNN Accuracy", "knn_accuracy", False),
            ("Shepard Correlation", "shepard_correlation", False),
            ("Silhouette Score", "silhouette_score", False),
            ("ARI", "ari_score", False),
            ("NMI", "nmi_score", False)
        ]
        
        for display_name, metric_key, lower_better in metrics_config:
            umap_val = umap_metrics.get(metric_key, 0.0)
            tsne_val = tsne_metrics.get(metric_key, 0.0)
            
            data.append({
                "M√©trique": display_name,
                "UMAP": f"{umap_val:.4f}",
                "t-SNE": f"{tsne_val:.4f}",
                "Meilleur": get_winner(umap_val, tsne_val, lower_better)
            })
        
        # Temps d'ex√©cution
        data.append({
            "M√©trique": "Temps d'ex√©cution (s)",
            "UMAP": f"{umap_time:.2f}",
            "t-SNE": f"{tsne_time:.2f}",
            "Meilleur": get_winner(umap_time, tsne_time, True)
        })
        
        # Clustering
        umap_n_clusters = umap_clustering.get('n_clusters', 0)
        tsne_n_clusters = tsne_clustering.get('n_clusters', 0)
        
        data.append({
            "M√©trique": "Nombre de clusters",
            "UMAP": str(umap_n_clusters),
            "t-SNE": str(tsne_n_clusters),
            "Meilleur": "-"
        })
        
        return pd.DataFrame(data)
    
    @staticmethod
    def format_metric_value(value: float, metric_name: str) -> str:
        """
        Formate une valeur de m√©trique pour l'affichage.
        
        Parameters
        ----------
        value : float
            Valeur √† formater
        metric_name : str
            Nom de la m√©trique
            
        Returns
        -------
        formatted : str
            Valeur format√©e
        """
        if np.isnan(value):
            return "N/A"
        elif np.isinf(value):
            return "‚àû"
        elif 'time' in metric_name.lower():
            return f"{value:.2f}s"
        elif 'stress' in metric_name.lower():
            return f"{value:.6f}"
        else:
            return f"{value:.4f}"

class ExportManager:
    """Gestionnaire pour l'export/import de sessions."""
    
    @staticmethod
    def export_session(session_state) -> str:
        """
        Exporte l'√©tat de la session vers un CSV.
        
        Parameters
        ----------
        session_state : streamlit.SessionState
            √âtat de la session Streamlit
            
        Returns
        -------
        csv_data : str
            Donn√©es CSV pr√™tes pour t√©l√©chargement
        """
        try:
            # Extraction des donn√©es principales
            data = {
                'x_umap': session_state.X_umap[:, 0].tolist(),
                'y_umap': session_state.X_umap[:, 1].tolist(),
                'x_tsne': session_state.X_tsne[:, 0].tolist(),
                'y_tsne': session_state.X_tsne[:, 1].tolist(),
                'labels': session_state.y.tolist(),
                'class_names': session_state.class_names
            }
            
            # M√©tadonn√©es de session
            metadata = {
                'dataset_choice': session_state.dataset_choice,
                'n_samples': len(session_state.y),
                'export_timestamp': pd.Timestamp.now().isoformat(),
                'umap_time': getattr(session_state, 't_umap', 0),
                'tsne_time': getattr(session_state, 't_tsne', 0)
            }
            
            # Cr√©ation du DataFrame
            df = pd.DataFrame({
                'x_umap': data['x_umap'],
                'y_umap': data['y_umap'], 
                'x_tsne': data['x_tsne'],
                'y_tsne': data['y_tsne'],
                'labels': data['labels']
            })
            
            # Ajout des m√©tadonn√©es comme premi√®re ligne de commentaire
            csv_buffer = io.StringIO()
            csv_buffer.write(f"# Session Metadata: {json.dumps(metadata)}\n")
            csv_buffer.write(f"# Class Names: {json.dumps(data['class_names'])}\n")
            
            # Export du DataFrame
            df.to_csv(csv_buffer, index=False)
            
            return csv_buffer.getvalue()
            
        except Exception as e:
            st.error(f"Erreur lors de l'export: {str(e)}")
            return ""
    
    @staticmethod
    def import_session(uploaded_file) -> Dict[str, Any]:
        """
        Importe une session depuis un fichier CSV.
        
        Parameters
        ----------
        uploaded_file : streamlit.UploadedFile
            Fichier upload√©
            
        Returns
        -------
        session_data : Dict[str, Any]
            Donn√©es de session import√©es
        """
        try:
            # Lecture du contenu
            content = uploaded_file.getvalue().decode('utf-8')
            lines = content.split('\n')
            
            # Extraction des m√©tadonn√©es depuis les commentaires
            metadata = {}
            class_names = []
            data_start_line = 0
            
            for i, line in enumerate(lines):
                if line.startswith('# Session Metadata:'):
                    metadata = json.loads(line.replace('# Session Metadata: ', ''))
                elif line.startswith('# Class Names:'):
                    class_names = json.loads(line.replace('# Class Names: ', ''))
                elif not line.startswith('#'):
                    data_start_line = i
                    break
            
            # Lecture des donn√©es principales
            data_lines = '\n'.join(lines[data_start_line:])
            df = pd.read_csv(io.StringIO(data_lines))
            
            # Construction du dictionnaire de session
            session_data = {
                'X_umap': df[['x_umap', 'y_umap']].values,
                'X_tsne': df[['x_tsne', 'y_tsne']].values,
                'y': df['labels'].values,
                'class_names': class_names,
                'metadata': metadata
            }
            
            return session_data
            
        except Exception as e:
            raise ValueError(f"Erreur lors de l'import: {str(e)}")
    
    @staticmethod
    def export_metrics_report(umap_metrics: Dict[str, float],
                            tsne_metrics: Dict[str, float],
                            comparison_df: pd.DataFrame,
                            filename: str = "metrics_report.html") -> str:
        """
        Exporte un rapport HTML des m√©triques.
        
        Parameters
        ----------
        umap_metrics : Dict[str, float]
            M√©triques UMAP
        tsne_metrics : Dict[str, float]
            M√©triques t-SNE
        comparison_df : pd.DataFrame
            Tableau de comparaison
        filename : str, default="metrics_report.html"
            Nom du fichier de sortie
            
        Returns
        -------
        filepath : str
            Chemin du fichier cr√©√©
        """
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>UMAP vs t-SNE - Rapport de M√©triques</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                h1, h2 {{ color: #2E86AB; }}
                table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
                th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
                th {{ background-color: #f2f2f2; font-weight: bold; }}
                .winner {{ background-color: #e8f5e8; font-weight: bold; }}
                .timestamp {{ color: #666; font-size: 12px; }}
            </style>
        </head>
        <body>
            <h1>UMAP vs t-SNE - Rapport de M√©triques</h1>
            <p class="timestamp">G√©n√©r√© le: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            
            <h2>Tableau Comparatif</h2>
            {comparison_df.to_html(escape=False, index=False)}
            
            <h2>M√©triques D√©taill√©es</h2>
            
            <h3>UMAP</h3>
            <ul>
                {"".join([f"<li><strong>{k}:</strong> {UIUtils.format_metric_value(v, k)}</li>" for k, v in umap_metrics.items()])}
            </ul>
            
            <h3>t-SNE</h3>
            <ul>
                {"".join([f"<li><strong>{k}:</strong> {UIUtils.format_metric_value(v, k)}</li>" for k, v in tsne_metrics.items()])}
            </ul>
        </body>
        </html>
        """
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        return filename

class ColorManager:
    """Gestionnaire de palettes de couleurs coh√©rentes."""
    
    # Palette principale (optimis√©e pour distinguabilit√©)
    PRIMARY_PALETTE = [
        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
        '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',
        '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5',
        '#c49c94', '#f7b6d3', '#c7c7c7', '#dbdb8d', '#9edae5'
    ]
    
    # Palette pour daltoniens
    COLORBLIND_PALETTE = [
        '#1f77b4', '#ff7f0e', '#d62728', '#2ca02c', '#9467bd',
        '#8c564b', '#e377c2', '#bcbd22', '#17becf', '#7f7f7f'
    ]
    
    @classmethod
    def get_palette(cls, n_colors: int, colorblind_friendly: bool = False) -> List[str]:
        """
        Retourne une palette de couleurs adapt√©e.
        
        Parameters
        ----------
        n_colors : int
            Nombre de couleurs n√©cessaires
        colorblind_friendly : bool, default=False
            Utiliser une palette adapt√©e aux daltoniens
            
        Returns
        -------
        palette : List[str]
            Liste de couleurs hexad√©cimales
        """
        base_palette = cls.COLORBLIND_PALETTE if colorblind_friendly else cls.PRIMARY_PALETTE
        
        if n_colors <= len(base_palette):
            return base_palette[:n_colors]
        else:
            # Extension de la palette si n√©cessaire
            extended_palette = base_palette.copy()
            
            # G√©n√©ration de couleurs additionnelles par variation
            import matplotlib.pyplot as plt
            import matplotlib.colors as mcolors
            
            try:
                additional_colors = plt.cm.Set3(np.linspace(0, 1, n_colors - len(base_palette)))
                extended_palette.extend([mcolors.rgb2hex(color[:3]) for color in additional_colors])
            except:
                # Fallback si erreur matplotlib
                for i in range(n_colors - len(base_palette)):
                    extended_palette.append('#888888')  # Gris par d√©faut
            
            return extended_palette[:n_colors]
    
    @staticmethod
    def create_gradient(start_color: str, end_color: str, n_steps: int) -> List[str]:
        """
        Cr√©e un d√©grad√© entre deux couleurs.
        
        Parameters
        ----------
        start_color : str
            Couleur de d√©but (hex)
        end_color : str
            Couleur de fin (hex)
        n_steps : int
            Nombre d'√©tapes du d√©grad√©
            
        Returns
        -------
        gradient : List[str]
            Liste de couleurs du d√©grad√©
        """
        try:
            import matplotlib.colors as mcolors
            
            # Conversion en RGB
            start_rgb = mcolors.hex2color(start_color)
            end_rgb = mcolors.hex2color(end_color)
            
            # G√©n√©ration du d√©grad√©
            gradient = []
            for i in range(n_steps):
                t = i / (n_steps - 1) if n_steps > 1 else 0
                
                r = start_rgb[0] + t * (end_rgb[0] - start_rgb[0])
                g = start_rgb[1] + t * (end_rgb[1] - start_rgb[1])
                b = start_rgb[2] + t * (end_rgb[2] - start_rgb[2])
                
                gradient.append(mcolors.rgb2hex((r, g, b)))
            
            return gradient
        
        except:
            # Fallback simple
            return [start_color] * n_steps


def save_best_params(dataset: str, model: str, params: dict, metric: str, score: float) -> Path:
    """
    Sauvegarde les meilleurs hyperparam√®tres pour un mod√®le et dataset donn√©.

    Parameters
    ----------
    dataset : str
        Nom du dataset
    model : str
        Nom du mod√®le (UMAP, t-SNE, etc.)
    params : dict
        Dictionnaire des hyperparam√®tres
    metric : str
        M√©trique utilis√©e pour l'√©valuation
    score : float
        Score obtenu

    Returns
    -------
    filepath : Path
        Chemin du fichier sauvegard√©
    """
    # Cr√©er le dossier si n√©cessaire
    output_dir = Path("outputs/runs") / dataset
    output_dir.mkdir(parents=True, exist_ok=True)

    # Pr√©parer les donn√©es √† sauvegarder
    data = {
        "model": model,
        "dataset": dataset,
        "params": params,
        "metric": metric,
        "score": score,
        "timestamp": pd.Timestamp.now().isoformat()
    }

    # Sauvegarder en JSON
    filepath = output_dir / f"{model}_best.json"
    with open(filepath, 'w') as f:
        json.dump(data, f, indent=2)

    return filepath


def load_best_params(dataset: str, model: str) -> Optional[dict]:
    """
    Charge les meilleurs hyperparam√®tres sauvegard√©s pour un mod√®le et dataset donn√©.

    Parameters
    ----------
    dataset : str
        Nom du dataset
    model : str
        Nom du mod√®le (UMAP, t-SNE, etc.)

    Returns
    -------
    params : dict or None
        Dictionnaire des hyperparam√®tres si trouv√©, sinon None
    """
    filepath = Path("outputs/runs") / dataset / f"{model}_best.json"

    if filepath.exists():
        try:
            with open(filepath, 'r') as f:
                data = json.load(f)
            return data.get("params", None)
        except Exception as e:
            warnings.warn(f"Erreur lors du chargement des param√®tres: {e}")
            return None

    return None